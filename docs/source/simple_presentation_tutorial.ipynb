{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating a simple Presentation Module\n",
    "\n",
    "**Before starting this tutorial please complete the** [first run](first_run.ipynb) **tutorial first to gain a general understanding of the components of this BCI.**\n",
    "\n",
    "*The non-Jupyter Notebook version of this code and other presentation examples can be found in the* [examples/presentation directory](https://github.com/mindaffect/pymindaffectBCI/blob/doc/mindaffectBCI/examples/presentation/minimal_presentation.py)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Presentation is inherently more complex than output as we must display the correct stimuli to the user with precise timing and communicate this timing information to the mindaffect decoder.  Further, for the BCI operation we need to operate in (at least),\n",
    "\n",
    "- _calibration_ mode where we cue the user where to attend to obtain correctly labelled brain data to train the machine learning algorithms in the decoder and\n",
    "- _prediction_ mode where the user actually uses the BCI to make selections.\n",
    "\n",
    "\n",
    "\n",
    "The *noisetag* module provides a number of tools to hide this complexity from the application developers.  Using the most extreem of these all the application developer has to do is provide a function to _draw_ the display as instructed by the noisetag module. To use it, we import the module and create the noisetag object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindaffectBCI.noisetag import Noisetag, sumstats\n",
    "nt = Noisetag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Draw function\n",
    "We will now write a fuction to draw the screen. Here we use the python gaming library [pyglet](www.pyglet.org) to draw 2 squares on the screen, with the given colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyglet\n",
    "# define a simple 2-squares drawing function\n",
    "def draw_squares(col1,col2):\n",
    "    # draw square 1: @100,190 , width=100, height=100\n",
    "    x=100; y=190; w=100; h=100;\n",
    "    pyglet.graphics.draw(4,pyglet.gl.GL_QUADS,\n",
    "                         ('v2f',(x,y,x+w,y,x+w,y+h,x,y+h)),\n",
    "             ('c3f',(col1)*4))\n",
    "    # draw square 2: @440,100\n",
    "    x=640-100-100\n",
    "    pyglet.graphics.draw(4,pyglet.gl.GL_QUADS,\n",
    "                         ('v2f',(x,y,x+w,y,x+w,y+h,x,y+h)),\n",
    "             ('c3f',(col2)*4))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the Display\n",
    "Now we write a function which, 1) asks the noisetag framework how the selectable squares should look, 2) updates the noisetag framework with information about how the display was updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary mapping from stimulus-state to colors\n",
    "state2color={0:(.2,.2,.2), # off=grey\n",
    "             1:(1,1,1),    # on=white\n",
    "             2:(0,1,0),    # cue=green\n",
    "             3:(0,0,1)}    # feedback=blue\n",
    "def draw(dt):\n",
    "    '''draw the display with colors from noisetag'''\n",
    "    # send info on the *previous* stimulus state, with the recorded vsync time (if available)\n",
    "    fliptime = window.lastfliptime if window.lastfliptime else nt.getTimeStamp()\n",
    "    nt.sendStimulusState(timestamp=fliptime)\n",
    "    # update and get the new stimulus state to display\n",
    "    try : \n",
    "        nt.updateStimulusState()\n",
    "        stimulus_state,target_state,objIDs,sendEvents=nt.getStimulusState()\n",
    "    except StopIteration :\n",
    "        pyglet.app.exit() # terminate app when noisetag is done\n",
    "        return\n",
    "\n",
    "    # draw the display with the instructed colors\n",
    "    if stimulus_state : \n",
    "        draw_squares(state2color[stimulus_state[0]],\n",
    "                     state2color[stimulus_state[1]])\n",
    "\n",
    "    # some textual logging of what's happening\n",
    "    if target_state is not None and target_state>=0:\n",
    "        print(\"*\" if target_state>0 else '.',end='',flush=True)\n",
    "    else:\n",
    "        print('.',end='',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step we integrate the behaviour of the output module created in the [Simple Output Tutuorial](simple_output_tutorial.ipynb) by attaching a selection callback which will be called whenever a selection is made by the BCI. For now we will use the \"Hello World\" example created in the Output Tutorial and add a function that prints the object ID of our second square when selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helloworld(objID):\n",
    "    print(\"hello world\")\n",
    "\n",
    "def printID(objID):\n",
    "    print(\"Selected: %d\"%(objID))\n",
    "    \n",
    "# define a trivial selection handler    \n",
    "def selectionHandler(objID):\n",
    "    selection_mapping = {\n",
    "        1:helloworld,\n",
    "        2:printID\n",
    "    }\n",
    "    func = selection_mapping.get(objID)\n",
    "    func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Accuracy \n",
    "Now, we need a bit of python hacking. Because our BCI depends on accurate timelock of the brain data (EEG) with the visual display, we need to have accurate time-stamps for when the display changes. Fortunately, pyglet allows us to get this accuracy as it provides a flip method on windows which blocks until the display is actually updated. Thus we can use this to generate accurate time-stamps. We do this by adding a time-stamp recording function to the windows normal flip method with the following magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def timedflip(self):\n",
    "    '''pseudo method type which records the timestamp for window flips'''\n",
    "    type(self).flip(self) # call the 'real' flip method...\n",
    "    self.lastfliptime=nt.getTimeStamp()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize the window to display the stimulus, and setup the flip-time recording for it.  Be sure that you have [vsync](https://en.wikipedia.org/wiki/Screen_tearing#Vertical_synchronization) turned-on. Many graphics cards turn this off by default, as it (in theory) gives higher frame rates for gaming. However, for our system, frame-rate is less important than exact timing, hence always turn vsync on for visual Brain-Compuber-Interfaces!  \n",
    "**Note:** always set ``fullscreen=True`` when using the presentation module to improve screen timing accuracy. We set it to ``False`` here so the tutorial stays visible when the stimulus is running.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the drawing window\n",
    "# make a default window, with fixed size for simplicty, and vsync for timing\n",
    "config = pyglet.gl.Config(double_buffer=True)\n",
    "window = pyglet.window.Window(fullscreen=False, width=640,height=480, vsync=True, config=config)\n",
    "\n",
    "# Setup the flip-time recording for this window\n",
    "window.flip = types.MethodType(timedflip,window)\n",
    "window.lastfliptime=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "To succesfully test your presentation module it is important to have the other components of the BCI running. As explained in the [first run tutorial](first_run.ipynb), additionally to the presentation we build here, we need the Hub, Decoder, and Acquisation components for a functioning BCI.  \n",
    "For a quick test (with fake data) of this presentation module you can launch all components from the terminal: \n",
    "\n",
    "```python3 -m mindaffectBCI.online_bci --config_file fake_recognizer.json``` \n",
    "\n",
    "Or from you Anacoda environment:   \n",
    "\n",
    "```python -m mindaffectBCI.online_bci --config_file fake_recognizer.json```\n",
    "\n",
    "**See our tutorial** [Running Custom Presentation](simple_integration_tutorial.ipynb) **to set-up a BCI using your own Presentation module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Experiment!\n",
    "To run the experiment we connect to the Hub, add our selection handler, tell the noisetag module to run a complete BCI 'experiment' with calibration and feedback mode, and start the pyglet main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the noise-tagging connection\n",
    "nt.connect(timeout_ms=5000)\n",
    "nt.addSelectionHandler(selectionHandler)\n",
    "\n",
    "# tell the noisetag framework to run a full : calibrate->prediction sequence\n",
    "nt.setnumActiveObjIDs(2)\n",
    "nt.startExpt(nCal=10,nPred=10,duration=4)\n",
    "\n",
    "# run the pyglet main loop\n",
    "pyglet.clock.schedule(draw)\n",
    "pyglet.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
